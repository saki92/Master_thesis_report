\chapter{Simulation Results and Evaluation}\label{ch:simulation}
In this chapter, we analyze the simulation results of our proposed techniques. We start by discussing the simulation setup. Then, we analyze the plots to evaluate the performance of our techniques.

\section{Experiment Setup}
For our simulations, we used the baseband system model described in Section~\ref{sec:sys_mod}. Table~\ref{tab:sim_param} lists the different parameters of the simulation setup. All the simulations are performed with these parameters unless otherwise specified.
\begin{table}[htbp]
\centering
\begin{tabular}{|l|c|r|}
  \hline
  \textbf{Parameter} &\textbf{Symbol} &\textbf{Value}\\
  \hline
  \hline
  Number of information bits &$n_i$ &3500\\
  \hline
  Codeword Length &$n_L$ &6390\\
  \hline
  Actual code rate &$R_L$ &$0.6216$\\
  \hline
  Asymptotic code rate &$R_\infty$ &$0.6667$\\
  \hline
  Number of termination bits &$m_t$ &380\\
  \hline
  Modulation &$o$ &\gls{qpsk}\\
  \hline
  Window size &$W$ &300\\
  \hline
  Maximal Number of iterations &$I$ &5\\
  \hline
  Number of runs &$\Gamma$ &4000\\
  \hline
\end{tabular}
\caption{Experimental settings for simulations.}
\label{tab:sim_param}
\end{table}

In most of our results we plot the \acrfull{bler} $P_L$ instead of \acrfull{ber} $P_b$ because in modern packet based transmission system, the whole block is discarded in physical layer if they are incorrect. So, it is better to evaluate the performance by \gls{bler} than \gls{ber}. We plot \acrfull{aneu} to measure the decoding complexity. All the simulations results are averaged over a number of runs specified in the Table~\ref{tab:sim_param}.
\section{Effect of Zero-tail Termination}
In Chapter~\ref{ch:encode} we concluded that the termination for \gls{bpl} codes are performed through zero-tail termination. Here, we evaluate the effect of zero-tail termination on the probability of error of each bit in the codeword. Figure~\ref{fig:eval_no_sat} shows the \gls{ber} $P_b(i)$ of each bit in the codeword when the zero-tail bits are not known at the receiver. Figure~\ref{fig:eval_sat} shows the \gls{ber} of each bit in the codeword when zero-tail bits are known at the receiver, i.e., at the decoder the \glspl{llr} of zero-tail bits are saturated to $+\infty$. The probabilities are calculated using (\ref{eq:indiv_prob}).  The plots include the information bits and the parity bits but do not include the termination sequence.
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_no_sat}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_no_sat}
  \caption[$P_b(i)$ when zero-tail bits are not known at receiver.]{Probability of error for information and parity bits in the codeword at $P_b=5\cdot 10^{-2}$. Zero-tail bits are not known at the receiver.}
  \label{fig:eval_no_sat}
\end{figure}

\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_sat}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_sat}
  \caption[$P_b(i)$ when zero-tail bits are known at receiver.]{Probability of error for information and parity bits in the codeword for $P_b=5\cdot 10^{-2}$. Zero-tail bits are known at the receiver.}
  \label{fig:eval_sat}
\end{figure}
 
From Figure~\ref{fig:eval_sat} we can see that when zero-tail bits are know at the receiver, the decoder reduces the $P_b(i)$ of the information and parity bits in the right of the codeword. Only the rightmost part of the codeword is affected because of the limited window size. With full-block decoder, the effect of having known bits would also improve the leftmost bits of the decoder. On the other hand, Figure~\ref{fig:eval_no_sat} shows that the lack of knowledge of zero-tail bits at the receiver does not reduce $P_b(i)$ at the end of the codeword. So, the knowledge of zero-tail bits at the decoder effectively reduces the \gls{cn} degrees at the right of the \gls{pcm} as in a properly terminated codeword. Hence, zero-tail termination is an acceptable alternative to proper termination.
 
\section{Evaluation of \texorpdfstring{\acrlong{bd}}{BD}}
Here, we analyze the performance and complexity of our \gls{bd} over different window sizes. Figure~\ref{fig:eval_bd_bler} shows the overall \gls{bler} $P_l$ over an \gls{snr} range of $2\leq\zeta\text{ (dB)}\leq 5$ for different window sizes. Figure~\ref{fig:eval_bd_aneu} shows the \gls{aneu} over the same range of \gls{snr}.
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_bd_bler}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_bd_bler}
  \caption[\acrshort{bler} vs \acrshort{snr} of the \acrshort{bd} for $W=300$.]{$P_L$ vs $\zeta$ of the \acrfull{bd}.}
  \label{fig:eval_bd_bler}
\end{figure}
\begin{figure}[htbp]
   \centering
   \tikzsetnextfilename{eval_bd_aneu}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_bd_aneu}
  \caption[\acrshort{aneu} vs \acrshort{snr} of the \acrshort{bd} for $W=300$.]{$\eta$ vs $\zeta$ of the \acrfull{bd}.}
  \label{fig:eval_bd_aneu}
\end{figure}

In Figure~\ref{fig:eval_bd_bler}, we see that the \gls{bler} improves with increasing window size $W$. When the window size is increased, more edges are included in the window enabling information to flow between a larger number of \glspl{vn}. At $P_L=10^{-1}$, the distance between $W=300$ and $W=600$ is about $1.1$ dB. Figure~\ref{fig:eval_bd_aneu} shows that the \gls{aneu} is high for larger window in the low-\gls{snr} region as the windows do not converge and thereby exhausts all iterations. In the waterfall region, i.e., the \gls{snr} domain where the \gls{bler} continuously decreases, larger windows converge quicker. For example at $\zeta=3.4$ dB, there is a $75\%$ decrease in \gls{aneu}. And in the error floor region, i.e., the \gls{snr} domain where there is no further decrease in \gls{bler}, the \gls{aneu} for all $W$ is about the same.

We also plot the performance over different code rates. Figure~\ref{fig:eval_bler_rate} shows different \gls{bler} plots for all available rates $R_\infty$ for \gls{bpl} codes. It is well known that codes with lower rate requires lower \gls{snr} to achieve the same \gls{bler} as the code with higher rates.
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_bler_rate}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_bler_rate}
  \caption[\acrshort{bler} vs \acrshort{snr} of the \acrshort{bd} for all $R_\infty$.]{$P_L$ vs $\zeta$ of the \acrfull{bd} for all available $R_\infty$ with $W=500$.}
  \label{fig:eval_bler_rate}
\end{figure}

%Finally, we compare the performance over $I=5,10$. Figure~\ref{fig:eval_bd_iter_bler_300} and Figure~\ref{fig:eval_bd_iter_aneu_300} shows the \gls{bd}'s performance and complexity over different number of iterations $I$ per window. We can see that the complexity is less for fewer $I=5$ but the performance of the decoder remains the same which indicates that the windows converge quicker, not utilizing all 5 iterations.
%\begin{figure}[htbp]
%  \centering
%  \tikzsetnextfilename{eval_bd_iter_bler_300}
%  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_bd_iter_bler_300}
%  \caption[Comparison of \acrshort{bler} of the \acrshort{bd} for different $I$.]{Comparison of \gls{bler} of the \acrfull{bd} for different $I$.}
%  \label{fig:eval_bd_iter_bler_300}
%\end{figure}
%\begin{figure}[htbp]
%  \centering
%  \tikzsetnextfilename{eval_bd_iter_aneu_300}
%  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_bd_iter_aneu_300}
%  \caption[Comparison of \acrshort{aneu} of the \acrshort{bd} for different $I$.]{Comparison of \gls{aneu} of the \acrfull{bd} for different $I$.}
%  \label{fig:eval_bd_iter_aneu_300}
%\end{figure}

\section{Evaluation of \texorpdfstring{\acrlong{lrl}}{LRL} Decoder}
Now, we compare the performance of \gls{lrl} decoder configuration-\rom{1}, \gls{lrl} decoder configuration-\rom{2} with the \gls{bd}. Figure~\ref{fig:eval_bd_lrl_bler} shows the $P_L$ of \gls{bd} and \gls{lrl} decoders with window size $W=300$. Similarly, Figure~\ref{fig:eval_bd_lrl_aneu} shows the $\eta$ of \gls{bd} and \gls{lrl} decoders with window size of $W=300$.
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_bd_lrl_bler}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_bd_lrl_bler}
  \caption[Comparison of \acrshort{bler} between the Base Decoder and \acrshort{lrl} decoder.]{Comparison of $P_L$ between the Base Decoder and \gls{lrl} decoder.}
  \label{fig:eval_bd_lrl_bler}
\end{figure}
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_bd_lrl_aneu}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_bd_lrl_aneu}
  \caption[Comparison of \acrshort{aneu} between the Base Decoder and \acrshort{lrl} decoder.]{Comparison of $\eta$ between the Base Decoder and \gls{lrl} decoder.}
  \label{fig:eval_bd_lrl_aneu}
\end{figure}

In Figure~\ref{fig:eval_bd_lrl_bler}, we see a significant decrease in $P_L$ of the \gls{lrl} decoder in both configurations compared to the \gls{bd}. Near the error-floor region where $P_L=1.5\cdot 10^{-4}$, there is a $\zeta$ gain of about $2.4$ dB. In the beginning of water-fall region where $P_L=3\cdot 10^{-1}$, there is a $\zeta$ gain of about $1.1$ dB. The gain in individual \gls{ber} $P_b(i)$ is seen in Figure~\ref{fig:eval_bd_lrl_iber}. We can see the just before the end-termination of the codeword, i.e., from bit 3500 to bit 4000, there is a $P_b(i)$ difference of $2\cdot 10^{-2}$. And in the rest of the codeword, there is a $P_b(i)$ difference of only $1\cdot 10^{-2}$. It indicates that the second phase of the \gls{lrl} decoder has improved the certainty of the bits through the information from the bits in the end-termination of the codeword. Hence, the proposed \gls{lrl} decoder is better than the \gls{bd} in terms of decoding performance.

In Figure~\ref{fig:eval_bd_lrl_aneu}, we see that the overall complexity of both \gls{lrl} are less than the complexity of \gls{bd}. In the water-fall region, i.e., starting from $\zeta=3$ dB there is a $27\%$ decrease in $\eta$ for both \gls{lrl} decoder configurations. The decrease is mainly because the second phase of the decoder propagates the reliable information from the end-termination to rest of the codeword, increasing the convergence speed of the windows. At low-\gls{snr} and water-fall region, we can notice that the \gls{lrl} configuration-\rom{2} decoder converges faster than the configuration-\rom{1} decoder. This faster convergence speed is because the target \gls{vn} are placed at the right side of the window and the \glspl{cn} are processed from bottom to top. On continuing through the water-fall region, the gap between \gls{bd} and \gls{lrl} decoder closes. At the error-floor region, the complexity of all three decoders are the same. At error-floor region, the \gls{snr} is so high that the \gls{bd} windows converges as quick as the \gls{lrl} decoders.
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_bd_lrl_iber}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_bd_lrl_iber}
  \caption[Individual \acrshort{ber} of \acrshort{bd} and \acrshort{lrl}.]{$P_b(i)$ for \gls{bd} and \gls{lrl} decoder for $W=500$ and $P_b=5\cdot 10^{-2}$.}
  \label{fig:eval_bd_lrl_iber}
\end{figure}

Figure~\ref{fig:eval_bd_lrl_bler_700} and Figure~\ref{fig:eval_bd_lrl_aneu_700} compares the performance and complexity between the \gls{bd} and both \gls{lrl} decoder configurations for window size $W=700$. We see that at the water-fall region where $P_L=9\cdot 10^{-2}$, the $\zeta$ gain is about $0.3$ db. This performance gain is very less compared to the gain obtained with $W=300$. The decrease in performance gain is because as the window size increases the \gls{bp}'s performance is better as seen in Figure~\ref{fig:eval_bd_bler}. Thus, further increasing the window size, increases the performance of both \gls{bd} and \gls{lrl} decoders by different steps and finally approaching the performance of a full-block decoder, i.e., a decoder with maximum $W$.

We see that as $W$ increases, there is a slight decrease in performance of \gls{lrl} configuration-\rom{2} decoder compared to configuration-\rom{1}. This difference in performance is because of the less window positions at the left side of the \gls{pcm} for \gls{lrl} configuration-\rom{2}. One could argue that the same factor would affect the performance of \gls{lrl} configuration-\rom{1} at the right side of the \gls{pcm} thus, on average yielding the same performance. But from Section~\ref{sec:bpl_termi}, we know that the start-termination has lower \gls{cn} degree than the zero-tailed end-termination. Hence, the more number of window positions allowed by the \gls{lrl} configuration-\rom{1} decreases the \gls{bler} compared to \gls{lrl} configuration-\rom{2}.
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_bd_lrl_bler_700}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_bd_lrl_bler_700}
  \caption[Comparison of \acrshort{bler} between the \acrshort{bd} and \acrshort{lrl} decoder with $W=700$]{Comparison of $P_L$ between the \gls{bd} and \gls{lrl} decoder with $W=700$.}
  \label{fig:eval_bd_lrl_bler_700}
\end{figure}
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_bd_lrl_aneu_700}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_bd_lrl_aneu_700}
  \caption[Comparison of \acrshort{aneu} between the \acrshort{bd} and \acrshort{lrl} decoder with $W=700$.]{Comparison of $\eta$ between the Base Decoder and \gls{lrl} decoder with $W=700$.}
  \label{fig:eval_bd_lrl_aneu_700}
\end{figure}

Next, we compare the performance of both window configurations of \gls{lrl} decoder. Table~\ref{tab:wind_conf} shows different window configurations used in simulation.
\begin{table}[htbp]
  \centering
  \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Simulation Configuration} &\textbf{First Phase} &\textbf{Second Phase}\\
    \hline
    \hline
    \gls{lrl} configuration-\rom{1} &Window configuration-\rom{1} &Window configuration-\rom{1}\\
    \hline
    \gls{lrl} configuration-\rom{2} &Window configuration-\rom{1} &Window configuration-\rom{2}\\
    \hline
  \end{tabular}
  \caption{\gls{lrl} decoder with different window configurations.}
  \label{tab:wind_conf}
\end{table}
Figure~\ref{fig:eval_comp_lrl_bler_300} compares the performance and Figure~\ref{fig:eval_comp_lrl_aneu_300} compares the complexity between both \gls{lrl} configurations. We see that the \gls{lrl} decoder with configuration-\rom{2} yields the same \gls{bler} performance as configuration-\rom{1} with a slightly reduced complexity. The \gls{ber} plot from Figure~\ref{fig:eval_comp_lrl_ber_300} also indicates the same. The reduced complexity is mainly because of the bottom to top \gls{cn} update in the second phase of the \gls{lrl} decoder configuration-\rom{2}. Also since the target \gls{vn} are in the right end of the window, the window converges faster than the configuration-\rom{1}.
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_comp_lrl_bler_300}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_comp_lrl_bler_300}
  \caption[Comparison of \acrshort{bler} between the \acrshort{lrl} config-\rom{1} and config-\rom{2}.]{Comparison of \gls{bler} between the \gls{lrl} decoders configuration-\rom{1} and configuration-\rom{2}.}
  \label{fig:eval_comp_lrl_bler_300}
\end{figure}
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_comp_lrl_ber_300}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_comp_lrl_ber_300}
  \caption[Comparison of \acrshort{ber} between the \acrshort{lrl} config-\rom{1} and config-\rom{2}.]{Comparison of \gls{ber} between the \gls{lrl} decoders configuration-\rom{1} and configuration-\rom{2}.}
  \label{fig:eval_comp_lrl_ber_300}
\end{figure}
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_comp_lrl_aneu_300}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_comp_lrl_aneu_300}
  \caption[Comparison of \acrshort{aneu} between the \acrshort{lrl} config-\rom{1} and config-\rom{2}.]{Comparison of \gls{aneu} between the \gls{lrl} decoders configuration-\rom{1} and configuration-\rom{2}.}
  \label{fig:eval_comp_lrl_aneu_300}
\end{figure}

\section{Evaluation of \texorpdfstring{\acrlong{ipsc}}{IPSC} Technique}
Here, we evaluate the performance of our \gls{ipsc} technique. Figure~\ref{fig:eval_ipsc_bler_300} and Figure~\ref{fig:eval_ipsc_aneu_300} compares the performance and complexity between the \gls{bd} with different convergence criteria with $W=300$. Similarly, Figure~\ref{fig:eval_ipsc_bler_600} and Figure~\ref{fig:eval_ipsc_aneu_600} compares for $W=600$.
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_ipsc_bler_300}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_ipsc_bler_300}
  \caption[Comparison of \acrshort{bler} between different convergence criteria for $W=300$.]{Comparison of \gls{bler} between different convergence criteria.}
  \label{fig:eval_ipsc_bler_300}
\end{figure}
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_ipsc_aneu_300}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_ipsc_aneu_300}
  \caption[Comparison of \acrshort{aneu} between different convergence criteria for $W=300$.]{Comparison of \gls{aneu} between different convergence criteria.}
  \label{fig:eval_ipsc_aneu_300}
\end{figure}
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_ipsc_bler_600}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_ipsc_bler_600}
  \caption[Comparison of \acrshort{bler} between different convergence criteria for $W=600$.]{Comparison of \gls{bler} between different convergence criteria with $W=600$.}
  \label{fig:eval_ipsc_bler_600}
\end{figure}
\begin{figure}[htbp]
  \centering
  \tikzsetnextfilename{eval_ipsc_aneu_600}
  \includegraphics[width=\textwidth,height=0.5\textheight]{plots/eval_ipsc_aneu_600}
  \caption[Comparison of \acrshort{aneu} between different convergence criteria for $W=600$.]{Comparison of \gls{aneu} between different convergence criteria with $W=600$.}
  \label{fig:eval_ipsc_aneu_600}
\end{figure}

From the Figures~\ref{fig:eval_ipsc_bler_300}, \ref{fig:eval_ipsc_aneu_300}, \ref{fig:eval_ipsc_bler_600} and \ref{fig:eval_ipsc_aneu_600} we see that for $W\geq2(m_s+1)$, checking only the target \glspl{cn} for convergence decreases the decoding complexity for $W>2m_s+1$. Hence, for convergence criteria it is better to use complete-\glspl{cn} if $W\leq2m_s+1$ and target-\glspl{cn} if $W>2m_s+1$.